## Methods

<span style="color:red">

### SV Genotyping Algorithm

The input to the SV genotyping algorithm is an indexed variation graph in `xg` format along with a (single-sample) read alignment in `GAM` format.
If the graph was constructed from a VCF, as was the case for the human-genome graphs discussed in this paper, this VCF can also be input to the caller.
The first step is to compute a compressed coverage index from the alignment using this command, `vg pack <graph.xg> <alignment.gam> -Q 5 -o graph.pack`.
This index stores the number of reads with mapping quality at least 5 mapped to each edge and each base of each node on the graph.
Computing the coverage can be done in a single scan through the reads and, in practice, tends to be an order of magnitude faster than sorting the reads.

Variation graphs, as represented in vg, are bidrected.
In a bidrected graph, every node can be thought of having two distinct *sides*.
See, for example, the left and right sides of each rectangle in Figure {@fig:vg-sv-cartoon}.
If *x* is the side of a given node *A*, then we use the notation *x'* to denote the other side of *A*.
A snarl is defined by a pair of sides, *x* and *y*, that satisfy the following criteria:
1. Removing all edges incident to *x'* and *y'* disconnects the graph, creating a connected component *X* that contains *x* and *y*.
2. There is no side *z* in *X* such that *{x,z}* satisfies the above criteria.  Likewise for *y*.

Snarls can be computed in linear time using a cactus graph decomposition [@tag:snarls].
They can be computed once for a given graph using `vg snarls`, or on the fly with `vg call`.

Once the snarls have been identified, the SV genotyping algorithm proceeds as follows.
For every snarl in the graph such that both its end nodes lie on a reference path (such as a chromosome) and that it is not contained in another snarl, the following steps are performed.

1. All VCF variants, *v1, v2, ..., vk* that are contained within the snarl are looked up using information embedded during graph construction.  Let *|vi|* be the number of alleles in the *ith* VCF variant.  Then there are *|v1|*x*|v2|*...x*|vk|* possible haplotypes through the snarl.  If this number is too high (>500k), then alleles with average support of less than 1 are filtered out.
2. For each possible haplotype, a bidrected path through the snarl (from *x* to *y*) is computed that corresponds to it.  Annotation information from the VCF that was embedded in the graph during construction is used for this.
3. For each haplotype path, its average support (over bases and edges) is computed using the compressed coverage index, and the two most-supported paths are selected (ties are broken arbitrarily).
4. If the most supported path exceeds the minimum support threshold (default 1), and has more than *B* (default 6) times the support of the next most supported path, the site is called homozygous for the allele associated with the most supported path.
5. Else if the second most supported path exceeds the minimum support threshold (default 1), then the site is deemed heterozygous with an allele from each of the top two paths.
6. Given the genotype computed above, it is trivial to map back from the chosen paths to the VCF alleles in order to produce the final output

The command to do the above is `vg call <graph.xg> -k <graph.pack> -v variants.vcf.gz`
If the graph was not constructed from a VCF, then a similar algorithm is used except the traversals are computed heuristically searching through the graph.
This is enabled by not using the `-v` option in the above command.

</span>


### toil-vg

toil-vg is a set of Python scripts for simplifying vg tasks such as graph construction, read mapping and SV genotyping.
Much of the analysis in this report was done using toil-vg, with the exact commands available at [github.com/vgteam/sv-genotyping-paper](https://github.com/vgteam/sv-genotyping-paper).
toil-vg  uses the Toil workflow engine [@tag:toil] to seamlessly run pipelines locally, on clusters or on the cloud.
Graph indexing, and mapping in particular are computationally expensive (though work is underway to address this) and well-suited to distribution on the cloid.
The principal toil-vg commands used are described below.

#### toil-vg construct

toil-vg construct automates graph construction and indexing following the best practices put forth by the vg community.
Graph construction is parallelized across different sequences from the reference FASTA, and different whole-genome indexes are created side by side when possible.
The graph is automatically annotated with paths corresponding to the different alleles in the input VCF.
The indexes created are the following:
* xg index: This is a compressed version of the graph that allows fast node, edge and path lookups
* gcsa2 index: This is a substring index used only for read mapping
* gbwt index: This is an index of all the haplotypes in the VCF as implied by phasing infromation.  When available, it is used to help ensure that haplotype information is preserved when constructing the gcsa2 index
* snarls index: The snarls represent sites of varition in the graph and are used for genotyping and variant calling.

#### toil-vg map

toil-vg map splits the input reads into batches, maps each batch in parallel, then merges the result.

#### toil-vg call

toil-vg call splits the input graph by chromosome and calls each one individually.
`vg call` has been recently updated so that this subdivision is largely unecessary: the entire graph can be easily called at once.
Still, toil-vg can be used to farm this task out to a single cloud node if desired. 

#### toil-vg sveval

toil-vg sveval evaluates the SV calls relative to a truth set.
The variants are first normalized with `bcftools norm` (1.9) to ensure consistent representation between called variants and baseline variants[@url:bcftools].
We then implemented an overlap-based strategy to compare SVs and compute evaluation metrics (sveval R package: [https://github.com/jmonlong/sveval](https://github.com/jmonlong/sveval)).
Figure {@fig:sveval} shows an overview of the SV evaluation approach which is described below.

For deletions and inversions, we begin by computing the overlaps between the SVs in the call set and the truth set.
For each variant we then compute the proportion of its region that is covered by a variant in the other set, considering only variants overlapping with at least 10% reciprocal overlap.
If this coverage proportion is higher than 50%, we consider the variant *covered*.
True positives (TPs) are covered variants from the call set (when computing the precision) or the truth set (when computing the recall).
Variants from the call set are considered false positives (FPs) if they are not covered by the truth set.
Conversely, variants from the truth set are considered false negatives (FNs) if they are not covered by the call set.

For insertions, we select pairs of insertions that are located no farther than 20 bp from each other.
We then align the inserted sequences using a Smith-Waterman alignment.
For each insertion we compute the proportion of its inserted sequence that aligns a matched variant in the other set.
If this proportion is at least 50% the insertions are considered covered.
Covering relationships are used to define TPs, FPs, and FNs the same way as for deletions and inversions.

The coverage statistics are computed using any variant larger than 1 bp but a minimum size is required for a variant to be counted as TP, FP, or FN.
In this work, we used the default minimum SV size of 50 bp.

sveval accepts VCF files with symbolic or explicit representation of the SVs.
If the explicit representation is used, multi-allelic variants are split and their sequences right-trimmed.
When using the explicit representation and when the REF and ALT sequences are longer than 10 bp, the reverse-complement of the ALT sequence is aligned to the REF sequence to identify potential inversions.
If more than 80% of the sequence aligns, it is classified as an inversion.

We assess both the ability to predict the presence of an SV as well as the full genotype.
For the *presence* evaluation, both heterozygous and homozygous alternate SVs are compared jointly using the approach described above.
To compute genotype-level metrics, the heterozygous and homozygous SVs are compared separately.
Before splitting the variants by genotype, pairs of heterozygous variants with reciprocal overlap of at least 80% are merged into a homozygous ALT variant.
To handle fragmented variants, consecutive heterozygous variants located at less that 20 bp from each other are first merged into larger heterozygous variants.

Precision-recall curves are produced by successively filtering out variants of low-quality.
By default the *QUAL* field in the VCF file is used as the quality information.
If *QUAL* is missing (or contains only 0s), the genotype quality in the *GQ* field is used.

The evaluation is performed using all variants or using only variants within high-confidence regions.
In most analysis, the high-confidence regions are constructed by excluding segmental duplications and tandem repeats (using the respective tracks from the UCSC Genome Browser).
For the GIAB analysis, we used the Tier 1 high-confidence regions provided by the GIAB consortium in version 0.6.


### Other SV genotypers

#### BayesTyper (v1.5 beta 62888d6)

Where not specified otherwise BayesTyper was run as follows.
Raw reads were mapped to the reference genome using bwa mem (citation: https://arxiv.org/abs/1303.3997) (0.7.17).
GATK haplotypecaller[@doi:10.1038/ng.806] (3.8) and Platypus[@doi:10.1038/ng.3036] (0.8.1.1) with assembly enabled were run on the mapped reads to call SNVs and short indels (<50bp) needed by BayesTyper for correct genotyping.
The VCFs with these variants were then normalised using `bcftools norm` (1.9) and combined with the SVs across samples using `bayesTyperTools combine` to produce the input candidate set. 
k-mers in the raw reads were counted using kmc (citation: https://academic.oup.com/bioinformatics/article/33/17/2759/3796399) (3.1.1) with a k-mer size of 55. 
A Bloom filter was constructed from these k-mers using `bayesTyperTools makeBloom`. 
Finally, variants were clustered and genotyped using `bayestyper cluster` and `bayestyper genotype`, respectively, with default parameters except `--min-genotype-posterior 0`. 
Non-PASS variants and non-SVs (GATK and Platypus origin) were filtered prior to evaluation using `bcftools filter` and `filterAlleleCallsetOrigin`, respectively.


#### Delly (v0.7.9)

The `delly call` command was run on the reads mapped by `bwa mem`, the reference genome FASTA file, and the VCF containing the SVs to genotype (converted to their explicit representations).

#### SVTyper (v0.7.0)

The VCF containing deletions was converted to symbolic representation and passed to `svtyper` with the reads mapped by `bwa mem`.
The output VCF was converted back to explicit representation using `bayesTyperTools convertAllele` to facilitate variant normalization before evaluation.

#### SMRT-SV v2 (v2.0.0 Feb 21 2019 commit adb13f2)

SMRT-SV v2 was run with the "30x-4" model and min-call-depth 8 cutoff.
It was run only on VCFs created by SMRT-SV, for which the required contig BAMs were available.
The Illumina BAMs used where the same as the other methods described above.
The output VCF was converted back to explicit representation to facilitate variant normalization later.

### Simulation experiment

We simulated a synthetic genome with 1000 insertions, deletions and inversions.
We separated each variant from the next by a buffer of at least 500 bp.
The sizes of deletions and insertions followed the distribution of SV sizes from the HGSVC catalog.
We used the same size distribution as deletions for inversions.
A VCF file was produced for three simulated samples with genotypes chosen uniformly between homozygous reference, heterozygous, and homozygous alternate.

We created another VCF file containing errors in the SV breakpoint locations.
We shifted one or both breakpoints of deletions and inversions by distances between 1 and 10 bp.
The locations and sequences of insertions were also modified, either shifting the variants or shortening them at the flanks, again by up to 10 bp. 

Paired-end reads were simulated using `vg sim` on the graph that contained the true SVs.
Different read depths were tested: 1x, 3x, 7x, 10x, 13x, 20x.
The base qualities and sequencing errors were trained to resemble real Illumina reads from NA12878 provided by the Genome in a Bottle Consortium.

The genotypes called in each experiment (genotyping method/VCF with or without errors/sequencing depth) were compared to the true SV genotypes to compute the precision, recall and F1 score (see [toil-vg sveval](#toil-vg-sveval)).

#### Breakpoint fine-tuning using graph augmentation

vg can call variants after augmenting the graph with the read alignments to discover new variants (see [toil-vg call](#toil-vg-call)).
We tested if this approach could fine-tune the breakpoint location of SVs in the graph.
We started with the graph that contained approximate SVs (1-10 bp errors in breakpoint location) and 20x simulated reads from the simulation experiment (see [Simulation experiment](#simulation-experiment)).
The variants called after graph augmentation were compared with the true SVs.
We considered fine-tuning correct if the breakpoints matched exactly.

### HGSVC Analysis

We first obtained phased VCFs for the three Human Genome Structural Variation Consortium (HGSVC) samples from Chaisson et al.[@tag:hgsvc] and combined them with `bcftools merge`.
A variation graph was created and indexed using the combined VCF and the HS38D1 reference with alt loci excluded.
The phasing information was used to construct a GBWT index[@doi:10.4230/LIPIcs.WABI.2018.4], from which the two haploid sequences from HG00514 were extracted as a graph.
Illumina read pairs with 30x coverage were simulated from these sequences using vg sim, with an error model learned from real reads from the same sample.
These simulated reads reflect an idealized situation where the breakpoints of the SVs being genotyped are exactly known *a priori*.
The reads were mapped to the graph, and the mappings used to genotype the SVs in the graph. 
Finally, the SV calls were compared back to the HG00514 genotypes from the HGSVC VCF.
We repeated the process with the same reads on the linear reference, using `bwa mem` for mapping and Delly, SVTyper and BayesTyper for SV genotyping.

We downloaded Illumina HiSeq 2500 paired end reads from the EBI's ENA FTP site for the three samples, using Run Accessions ERR903030, ERR895347 and ERR894724 for HG00514, HG00733 and NA19240, respectively.
We ran the graph and linear mapping and genotyping pipelines exactly as for the simulation, and aggregated the comparison results across the three samples.
We used BayesTyper to jointly genotype the 3 samples.

### GIAB Analysis


We obtained version 0.5 of the Genome in a Bottle (GIAB) SV VCF for the Ashkenazim son (HG002) and his parents from the NCBI FTP site.
We obtained Illumina reads as described in Garrison et al.[@tag:vgnbt] and downsampled them to 50x coverage.
We used these reads as input for `vg call` and the other SV genotyping pipelines described above (though with GRCh37 instead of GRCh38).
For BayesTyper, we created the input variant set by combining the GIAB SVs with SNV and indels from the same study.
Variants with reference allele or without a determined genotype for HG002 in the GIAB call set (10,569 out of 30,224) were considered "false positives" as a proxy measure for precision.
These variants correspond to putative technical artifacts and parental calls not present in HG002.
For the evaluation in high confidence regions, we used the Tier 1 high-confidence regions provided by the GIAB consortium in version 0.6.

### SMRT-SV v2 Comparison (CHMPD and SVPOP)

The SMRT-SV v2 genotyper can only be used to genotype sequence-resolved SVs present on contigs with known SV breakpoints, such as those created by SMRT-SV v2, and therefore could not be run on the simulated, HGSVC, or GIAB call sets.
The authors shared their training and evaluation set: a pseudodiploid sample constructed from combining the haploid CHM1 and CHM13 samples (CHMPD), and a negative control (NA19240). 
The high quality of the CHM assemblies makes this set an attractive alternative to using simulated reads.
We used this two-sample pseudodiploid VCF along with the 30X read set to construct, map and genotype with vg, and also ran SMRT-SV v2 genotyper with the "30x-4" model and min-call-depth 8 cutoff, and compared the two back to the original VCF.

In an effort to extend this comparison from the training data to a more realistic setting, we reran the three HGSVC samples against the SMRT-SV v2 discovery VCF (SVPOP, which contains 12 additional samples in addition to the three from HGSVC) published by Audano et al.[@tag:audano2019] using vg and SMRT-SV v2 Genotyper.
The discovery VCF does not contain genotypes.
In consequence, we were unable to distinguish between heterozygous and homozygous genotypes, and instead considered only the presence or absence of a non-reference allele for each variant.

SMRT-SV v2 produces explicit *no-call* predictions when the read coverage is too low to produce accurate genotypes.
These no-calls are considered homozygous reference in the main accuracy evaluation.
We also explored the performance of vg and SMRT-SV v2 in different sets of regions (Figure {@fig:svpop-regions} and Table {@tbl:svpop-regions}):

1. Non-repeat regions, i.e. excluding segmental duplications and tandem repeats (using the respective tracks from the UCSC Genome Browser).
1. Repeat regions defined as segmental duplications and tandem repeats.
1. Regions where SMRT-SV v2 could call variants.
1. Regions where SMRT-SV v2 produced no-calls.

### Yeast graph analysis

For the analysis of graphs from *de novo* assemblies, we utilized publicly available PacBio-derived assemblies and Illumina short read sequencing datasets for 12 yeast strains from two related clades (Table {@tbl:strains}) [@doi:10.1038/ng.3847].
We constructed graphs from two different strain sets:
For the *five strains set*, we selected five strains for graph contruction (*S.c. SK1*, *S.c. YPS128*, *S.p. CBS432*, *S.p. UFRJ50816* and *S.c. S288C*).
We randomly selected two strains from different subclades of each clade as well as the reference strain *S.c. S288C*.
For the *all strains set* in contrast, we utilized all twelve strains for graph contruction.
We constructed two different types of genome graphs from the PacBio-derived assemblies of the five or twelve (depending on the strains set) selected strains.
In this section, we describe the steps for the construction of both graphs and the <span style="color:red">genotyping</span>~~calling~~ of variants.
More details and the precise commands used in our analyses can be found at [github.com/vgteam/sv-genotyping-paper](https://github.com/vgteam/sv-genotyping-paper).


| Strain      | Clade         | Included in *five strains set* | Included in *all strains set* |
|-------------|---------------|--------------------------------|--------------------------------|
| S288C       | S. cerevisiae | ✓                              | ✓                              |
| SK1         | S. cerevisiae | ✓                              | ✓                              |
| YPS128      | S. cerevisiae | ✓                              | ✓                              |
| UWOPS034614 | S. cerevisiae |                                | ✓                              |
| Y12         | S. cerevisiae |                                | ✓                              |
| DBVPG6765   | S. cerevisiae |                                | ✓                              |
| DBVPG6044   | S. cerevisiae |                                | ✓                              |
| CBS432      | S. paradoxus  | ✓                              | ✓                              |
| UFRJ50816   | S. paradoxus  | ✓                              | ✓                              |
| N44         | S. paradoxus  |                                | ✓                              |
| UWOPS919171 | S. paradoxus  |                                | ✓                              |
| YPS138      | S. paradoxus  |                                | ✓                              |

Table: 12 yeast strains from two related clades were used in our analysis. Five strains were selected to be included in the *five strains set* and all strains were included in the *all strains set*. Graphs were constructed from strains in the respective strain set while all eleven non-reference strains were used for <span style="color:red">genotyping</span>~~variant calling~~. {#tbl:strains}

#### Construction of the *VCF graph*

We constructed the first graph (called the *VCF graph* throughout the paper) by adding variants onto a linear reference. 
This method requires one assembly to serve as a reference genome.
The other assemblies must be converted to variant calls relative to this reference.
The PacBio assembly of the S.c. S288C strain was chosen as the reference genome because this strain was used for the S. cerevisiae genome reference assembly.
To obtain variants for the other assemblies, we combined three methods for SV detection from genome assemblies: Assemblytics [@doi:10.1093/bioinformatics/btw369] (commit df5361f), AsmVar (commit 5abd91a) [@doi:10.1186/s13742-015-0103-4] and paftools (version 2.14-r883) [@doi:10.1093/bioinformatics/bty191].
We constructed a union set of SVs detected by the three methods (using bedtools [@doi:10.1093/bioinformatics/btq033]), and combined variants with a reciprocal overlap of at least 50% to avoid duplication in the union set.
We merged these union sets of variants for each of the other (non-reference) strains in the strain set, and we then applied another deduplication step to combine variants with a reciprocal overlap of at least 90%.
We then used `vg construct` to build the *VCF graph* with the total set of variants and the linear reference genome.

#### Construction of the *cactus graph*

The second graph (called the *cactus graph* throughout the paper) was constructed from a whole genome alignment between the assemblies.
First, the repeat-masked PacBio-assemblies of the strains in the strain set were aligned with our Cactus tool [@doi:10.1101/gr.123356.111].
Cactus requires a phylogenetic tree of the strains which was estimated using Mash (version 2.1) [@doi:10.1186/s13059-016-0997-x] and PHYLIP (version 3.695) [@raw:phylip].
Subsequently, we converted the HAL format output file to a variation graph with hal2vg ([https://github.com/ComparativeGenomicsToolkit/hal2vg](https://github.com/ComparativeGenomicsToolkit/hal2vg)).

#### ~~Calling and~~ Genotyping of SVs

Prior to <span style="color:red">genotyping</span>~~variant calling~~, we mapped the Illumina short reads of all 12 yeast strains to both graphs using `vg map`.
We measured the fractions of reads mapped with specific properties using `vg view` and the JSON processor `jq`.
Then, we applied `toil-vg call` (commit be8b6da) to <span style="color:red">genotype</span>~~call~~ variants, obtaining a separate <span style="color:red">genotype</span>~~variant call~~ set for each of the 11 non-reference strains on both graphs and for each of the two strain sets (in total 11 x 2 x 2 = 44 <span style="color:red">genotype</span>~~call~~ sets).
From the <span style="color:red">genotype</span>~~call~~ sets, we removed variants smaller than 50 bp and variants with missing or homozygous reference genotypes.
To evaluate the filtered <span style="color:red">genotype</span>~~call~~ sets, we generated a sample graph (i.e. a graph representation of the <span style="color:red">genotype</span>~~call~~ set) for each <span style="color:red">genotype</span>~~call~~ set using `vg construct` and `vg mod` on the reference assembly *S.c. S288C* and the <span style="color:red">genotype</span>~~call~~ set.
Subsequently, we mapped short reads from the respective strains to each sample graph using `vg map`.
We mapped the short reads also to an empty sample graph that was generated using `vg construct` as a graph representation of the linear reference genome.
In an effort to restrict our analysis to SV regions, we removed reads that mapped equally well (i.e. with identical mapping quality and percent identity) to all three graphs (the two sample graphs and the empty sample graph) from the analysis.
These filtered out reads most likely stem from portions of the strains' genomes that are identical to the reference strain *S.c. S288C*.
We analyzed the remaining alignments of reads from SV regions with `vg view` and `jq`.

